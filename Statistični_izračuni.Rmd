---
title: "Priloga - Statistični izračuni za primerjave povprečji in deležev med dvema vzorcema"
author: "Luka Štrlekar"
output: pdf_document
editor_options: 
  chunk_output_type: console
fontsize: 12pt
header-includes:
  - \usepackage{setspace}\spacing{1.15}
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = FALSE)
```

# Izračuni za številske (intervalne) spremenljivke

## Neuteženi podatki

Želimo primerjati povprečja ($\mu_1$ in $\mu_2)$ iz dveh neodvisnih vzorcev (skupin) in ugotoviti ali se na populaciji razlikujeta. Ničelna domneva je $H_0: \mu_1=\mu_2$, torej, da sta povprečji enaki. Za preverjanje slednje ničelne domneve uporabimo *t-test* za neenake variance (t.i. *Welchev t-test*), ki med drugim predpostavlja normalno porazdelitev povprečji v obeh skupinah oziroma dovolj velik vzorec (v vsaki skupini), da velja centralni limitni izrek (običajno pravilo čez palec $n \geq 30$).

Ker sta vzorca neodvisna, velja $Var(\mu_1 - \mu_2) = \frac{\sigma^2_1}{n_1} + \frac{\sigma^2_2}{n_2}$. Na vzorcu ocenimo testno statistiko:

\begin{equation}
T = \frac{\hat{\mu}_1 - \hat{\mu}_2}{\sqrt{\frac{{\hat\sigma}^2_1}{n_1} + \frac{\hat{\sigma}^2_2}{n_2}}} 
\end{equation}
ki je približno porazdeljena po $t$ porazdelitvi z $\nu$ stopinjami prostosti (df) izračunanimi po naslednji formuli:

$$
\nu \approx \dfrac{\left(\hat{\sigma}_{1}^{2} / n_{1}+\hat{\sigma}_{2}^{2} / n_{2}\right)^{2}}{\left(\hat{\sigma}_{1}^{2} / n_{1}\right)^{2} /\left(n_{1}-1\right)+\left(\hat{\sigma}_{2}^{2} / n_{2}\right)^{2} /\left(n_{2}-1\right)}
$$
Pogosto prakso, ki je npr. implementirana v SPSS, da se najprej preveri enakost varianc (npr. z Levenovim testom) in nato uporabi ustrezen t-test (z enakimi ali neenakimi variancami), se odsvetuje (Zimmerman, 2010). Welchev t-test se lahko privzeto uporabi vsakič, saj je tudi moč tega testa podobna t-testu z enakimi variancami v primeru enakih populacijskih varianc in uravnoteženih vzorcev (Ruxton, 2006).

## Uteženi podatki

Vzorčno uteženo aritmetično sredino lahko v splošnem zapišemo kot ($w_i$ so uteži) (Kalton & Vehovar, 2001, str. 93):

\begin{equation}
\mu_w = \frac{\sum^n_{i=1} w_i x_i}{\sum^n_{i=1} w_i}
\end{equation}

Oglejmo si še oceno vzorčne variance. Ker ima utežena aritmetična sredina slučajni spremenljivki v števcu in v imenovalcu, je variabilnost odvisna od variabilnosti slučajnih spremenljivk tako v števcu kot v imenovalcu, kot tudi od njihove korelacije. Ker ne obstaja natančna analitična oblika za izračun te variance, se za približno oceno uporabljajo različne metode, predvsem Taylorjeva linearizacija ali metode replikacij kot je bootstrap/jackknife (Kalton & Vehovar, 2001).

Uporaba Taylorjeve linearizacije, kar imenujemo tudi metoda delta, poda naslednjo cenilko za vzorčno varianco utežene aritmetične sredine, pri čemer predpostavljamo, da so uteži fiksne (izhajajo iz neenakih verjetnosti izbora enote v vzorec) (Gatz & Smith, 1995; Lohr, 2019):

\begin{equation}
var(\mu_w) \approx \frac{n}{(n-1)(\sum{w_i} )^2}  \sum w_i^2(x_i - \mu_w)^2
\end{equation}

Zgornjo formulo lahko zapišemo tudi na spodnji način, kjer je bolj razvidno, da v izračun vstopa tudi kovarianca (Kalton & Vehovar, 2001, str. 95, $u_i = w_ix_i$):

\begin{equation}
var(\mu_w) \approx \frac{var(u) n + {\mu}_w^2 var(w) n - 2 {\mu}_w cov(u,w) n}{(\sum{w_i})^2}
\end{equation}

V praksi sicer prevladuje prepričanje, da je vpliv obravnavane korelacije majhen, saj običajno ni posebnih razlogov za izrazitejšo povezanost med utežmi in vrednostmi spremenljivk, pa tudi vpliv korelacije ni neposreden, ampak je precej kompleksen. Po drugi strani velja opozoriti, da je korelacija med utežmi in spremenljivko - na nivoju celotnega vzorca - predpogoj za nastanek in tudi za zmanjšanje pristranskosti neutežene ocene (Kalton & Vehovar, 2001, str. 111). 

Velja pa poudariti, da smo predpostavljali, da so uteži fiksne in se pri ponavljajočem izbiranju vzorca ne spreminjajo, kar pa pri poststratifikacijskem uteževanju ne velja. Vseeno je ta ocena vzorčne variance varna (tj. konzervativna) (Lu in Gelman, 2003; Lumley, 2011).

Podobno kot pri neuteženih podatkih ocenimo testno statistiko:

$$
T_w = \frac{\hat{\mu}_{w1} - \hat{\mu}_{w2}}{\sqrt{var(\hat{\mu}_{w1}) + var(\hat{\mu}_{w2})}} 
$$


```{r, eval=FALSE}
d = data.frame(uc = c(2,5,6,8,3,7,6,3,5,2),
               sm = c(1,2,3,3,2,4,4,2,3,2),
               utez = c(12,6,4,4,6,3,3,6,4,6))
d$u <- d$uc * d$utez

up = weighted.mean(d$uc, w = d$utez)

(var(d$u)*10 + up^2*var(d$utez)*10-2*up*10*cov(d$u, d$utez))/(sum(d$utez)^2)

cor(d$uc, d$utez)
cor(d$u, d$utez)
```


# Izračuni za opisne (nominalne) spremnljivke

## Neuteženi podatki

Imamo nominalno spremenljivko s $k$ kategorijami. Delež je pravzaprav povprečje binomsko porazdeljene slučajne spremenljivke (lahko zavzame vrednosti 0 in 1, $\sim \frac{1}{n}Binom(n,p)$). V našem primeru taka spremenljivka zavzame vrednost 1, če je v $k$-ti kategoriji in 0, če ni (skupaj $n$ vrednosti). Ne želimo preverjati ničelne domneve, da so hkrati deleži vseh kategorij enaki ($H_0:p_1= p_2=\ ...\ = p_k$), temveč želimo preveriti ničelno domnevo, da je delež v $k$-ti kategoriji v prvem vzorcu (skupini) enak deležu v isti kategoriji v drugem vzorcu ($H_0:p_{1}=p_{2}$).

Ocenimo običajno testno statistiko:

$$
Z = \frac{\hat{p}_1 - \hat{p}_2}{\sqrt{\hat{p}(1 - \hat{p})\left(\frac{1}{n_1} + \frac{1}{n_2}\right)}}
$$
, kjer je
$$
\hat{p}=\frac{n_1 \hat{p}_1+n_2 \hat{p}_2}{n_1+n_2}
$$
, ki je ob izpolnjenih pogojih (dovolj velik vzorec v obeh skupinah - pravilo čez palec $np>5$ in $n(1-p)>5$) porazdeljena približno po standardni normalni ($z$) porazdelitvi.

## Uteženi podatki

Ker v literaturi ne obstaja formula za skupen (*pooled* - $\hat{p}$) utežen delež, ocenimo standardno napako kar po formuli (3) za vsak delež posebej (kot smo že omenili, je delež povprečje dihotomne spremenljivke), saj v primeru neodvisnih vzorcev velja $Var(p_{1}-p_{2})=Var(p_1) + Var(p_2)$.

Testna statistika za utežen delež je torej:

$$
Z_w = \frac{\hat{p}_{w1} - \hat{p}_{w2}}{\sqrt{var(\hat{p}_{w1}) + var(\hat{p}_{w2})}} 
$$

```{r, eval=FALSE}
# Simulacije (izračun vzorčne variance)
library(tidyverse)
library(anesrake)
library(survey)

generate_data <- function(n, beta0 = 10, beta1 = 3, sigma = 2, pA){
  data <- data.frame(row.names = seq_len(n))
  
  data$spremenljivka_X <- sample(1:4, size = n, replace = TRUE, prob = c(0.3, 0.3, 0.3, 0.1))
  
  # vrednosti slučajnih napak
  epsilon <- rnorm(n, mean = 0, sd = sigma)
  
  data$spremenljivka_Y <- (beta0 + beta1*data$spremenljivka_X + epsilon)
  
  data$spremenljivka_A <- sample(x = 0:1, size = n, replace = TRUE, prob = c(1-pA, pA))
  
  data$spremenljivka_X <- as.factor(data$spremenljivka_X)
  data$spremenljivka_A <- as.factor(data$spremenljivka_A)
  
  return(data)
}


spremenljivka_X_target <- c(0.3, 0.3, 0.3, 0.1)
names(spremenljivka_X_target) <- 1:4

spremenljivka_A_target <- c(0.5, 0.5)
names(spremenljivka_A_target) <- 0:1

targets <- list(spremenljivka_X_target, spremenljivka_A_target)

names(targets) <- c("spremenljivka_X", "spremenljivka_A")

n <- 1000

caseid <- 1:n

n_sim <- 500

results <- matrix(data = rep(NA, 12*n_sim), ncol = 12,
                  dimnames = list(NULL,
                                  c("povp", "utezeno_povp", "cor", "var_utezi", "se2/n", "se_w2/n", "se_cov", "se_VIF", "se_w", "cov", "bias", "var_cov")))

for(i in 1:n_sim){
  data <- generate_data(n = n, beta0 = 3, beta1 = 10, sigma = 1, pA = 0.6)
  x <- data$spremenljivka_Y

  # RAKING
  # weights <- anesrake::anesrake(targets, data, caseid = caseid, type = "nolim")$weightvec

  # data$utezi <- weights
  design <- svydesign(ids = ~1, data = data)

  rr <- rake(design, list(~spremenljivka_X,~spremenljivka_A),
             list(data.frame(spremenljivka_X = 1:4, Freq = spremenljivka_X_target*1000),
                  data.frame(spremenljivka_A = 0:1, Freq = spremenljivka_A_target*1000)))
  # 
  weights <- weights(rr)
  
  # all.equal(weights, weights2)
  
  # SHRANIMO REZULTATE
  # neuteženo povprečje
  results[i,1] <- mean(data$spremenljivka_Y)
  # uteženo povprečje
  mu <- weighted.mean(x = data$spremenljivka_Y, w = weights)
  results[i,2] <- mu
  # korelacija med utežmi in spremenljivko Y
  results[i,3] <- cor(data$spremenljivka_Y, weights)
  
  # varianca uteži
  results[i,4] <- var(weights)
  
  # se^2/n
  results[i,5] <- var(data$spremenljivka_Y)/n
  # se_w^2/n
  results[i,6] <- Hmisc::wtd.var(x = data$spremenljivka_Y, weights = weights)/n
  # se_cov
  u <- weights * data$spremenljivka_Y
  results[i,7] <- (n * var(u) + mu^2 * n * var(weights) - 2 * mu * n * cov(u, weights))/(sum(weights)^2)
  # se VIF
  results[i,8] <- (var(data$spremenljivka_Y)/n) * (1 + var(weights))
  # se wiki
  results[i,9] <- (1/sum(weights)^2) * sum(weights^2 * (data$spremenljivka_Y - mu)^2) 
  # boot
  # boot_mu <- vector("numeric", 10L)
  # for(j in 1:10){
  #   data_boot <- data[sample(1:n, n, replace=TRUE),]
  #   weights_boot <- anesrake::anesrake(targets, data_boot, caseid = caseid, type = "nolim")$weightvec
  #   boot_mu[j] <- weighted.mean(x = data_boot$spremenljivka_Y, w = weights_boot)
  # }
  
  results[i,10] <- cov(data$spremenljivka_Y, weights)
  results[i,11] <- mu - mean(data$spremenljivka_Y)
  
  # bootstrap SE
  # samps <- lapply(1:1000, function(g) sample(1:length(x), round(sum(weights, na.rm=TRUE), 0), replace=TRUE, prob=weights))
  # sepests <- sapply(samps, function(q) mean(x[q], na.rm=TRUE))
  

  results[i,12] <- SE(svymean(data$spremenljivka_Y, rr))^2
}



hist(results[,1], breaks = 50, freq = FALSE)
hist(results[,2], breaks = 50, freq = FALSE)

var(results[,1])
var(results[,2])
mean(results[,5])
mean(results[,6])
mean(results[,7])
mean(results[,8])
mean(results[,9])
mean(results[,12])

# bias je praktično enak kovarianci med utežjo in spr.
mean(results[,10])
mean(results[,11])

# korelacija med utežmi in ciljno spremenljivko
mean(results[,3])



# https://www.alexstephenson.me/post/2022-04-02-weighted-variance-in-r/#fn1
weighted.se.mean <- function(x, w, na.rm = T){
    ## Remove NAs 
    if (na.rm) {
      i <- !is.na(x)
        w <- w[i]
        x <- x[i]
    }
    
    ## Calculate effective N and correction factor
    n_eff <- (sum(w))^2/(sum(w^2))
    correction = n_eff/(n_eff-1)
    
    ## Get weighted variance 
    numerator = sum(w*(x-weighted.mean(x,w))^2)
    denominator = sum(w)
    
    ## get weighted standard error of the mean 
    se_x = (correction * (numerator/denominator))/n_eff
    return(se_x)
}


weighted.se.mean2 <- function(x, weights_x){
  i <- !is.na(x)
  x <- x[i]
  weights_x <- weights_x[i]
  # weights_x <- weights_x/mean(weights_x)
  
  mu1 = weighted.mean(x, weights_x)
  # u1 <- x * weights_x
  # se1 <- (var(u1, na.rm = TRUE) + mu1^2 * var(weights_x, na.rm = TRUE) - 2 * mu1 * cov(u1, weights_x))/(sum(weights_x, na.rm = TRUE))
  # se1
  
  n <- sum(!is.na(x))
  
  u1 <- weights_x * x
  se1 <- (n * var(u1) + mu1^2 * n * var(weights_x) - 2 * mu1 * n * cov(u1, weights_x))/(sum(weights_x)^2)
  se1
}

weighted.se.mean3 <- function(x, weights){
  i <- !is.na(x)
  x <- x[i]
  weights <- weights[i]
  weights <- weights/mean(weights)
  
  mu = weighted.mean(x, weights)
  (1/sum(weights)^2) * sum(weights^2 * (x - mu)^2)
}

weighted.se.mean4 <- function(x, weights){
  # n = length(x)
  # survey dobimo identično SE, razen če so manjkajoče vrednosti ko survey zgleda vzame kar cel n kot je bila baza
  # ali je ta n št. clustrov (po Lohr)
  i <- !is.na(x)
  x <- x[i]
  weights <- weights[i]
  # weights <- weights/mean(weights)
  
  n = sum(!is.na(x))

  mu = weighted.mean(x, weights, na.rm = TRUE)
  (n/((n-1)*sum(weights)^2)) * sum(weights^2 * (x - mu)^2)
}

weighted.se.mean5 <- function(x, weights){
  i <- !is.na(x)
  x <- x[i]
  weights <- weights[i]
  weights <- weights/sum(weights)
  n = sum(!is.na(x))
  
  mu = weighted.mean(x, weights)
  sum(weights^2 * (x - mu)^2)
}

weighted.se.mean(baza1[[stevilske_spremenljivke[3]]], utezi1)
weighted.se.mean3(baza1[[stevilske_spremenljivke[3]]], utezi1)

weighted.se.mean2(baza1[[stevilske_spremenljivke[3]]], utezi1) # ISTO !!!
weighted.se.mean4(baza1[[stevilske_spremenljivke[3]]], utezi1)
weighted.se.mean5(baza1[[stevilske_spremenljivke[3]]], utezi1)

weighted.se.mean5(baza1[[stevilske_spremenljivke[3]]], utezi1) #ISTO
wtd.var(baza1[[stevilske_spremenljivke[3]]], utezi1)/sum(!is.na(baza1[[stevilske_spremenljivke[3]]]))
```

```{r, eval=FALSE}
library(survey)
ds <- svydesign(ids = ~1, data = baza1, weights = utezi1)

as.numeric(SE(svymean(baza1[[stevilske_spremenljivke[3]]], design = ds, na.rm = T))^2)

svy<-NULL
me<-NULL
for(i in seq_along(stevilske_spremenljivke)){
  svy <- c(svy, as.numeric(SE(svymean(baza1[[stevilske_spremenljivke[i]]], design = ds, na.rm = T))^2))
  me <- c(me, weighted.se.mean4(baza1[[stevilske_spremenljivke[i]]], baza1$weights))
}

all.equal(svy, me)


data(api)
apiclus1$spol <- as.factor(sample(0:1, size = 183, replace = T, prob = c(0.5, 0.5)))
dclus1<-svydesign(id = ~1, data=apiclus1, weights = ~pw)

```


# Viri

Gatz, D. F., & Smith, L. (1995). The standard error of a weighted mean concentration—I. Bootstrapping vs other methods. *Atmospheric Environment, 29*(11), 1185-1193.

Kalton, G. & Vehovar, V. (2001). *Vzorčenje v anketah*. Ljubljana : Fakulteta za družbene vede

Lohr, S.L. (2019). *Sampling: Design and Analysis (2nd ed.)*. Chapman and Hall/CRC. https://doi.org/10.1201/9780429296284

Lu, H., & Gelman, A. (2003). A method for estimating design-based sampling variances for surveys with weighting, poststratification, and raking. *Journal of Official Statistics, 19*(2), 133-151.

Lumley, T. (2011). *Complex surveys: a guide to analysis using R*. John Wiley & Sons.

Ruxton, G. D. (2006). The unequal variance t-test is an underused alternative to Student's t-test and the Mann-Whitney U test. *Behavioral Ecology, 17*(4), 688-690.

Zimmerman, D. W. (2004). A note on preliminary tests of equality of variances. *British Journal of Mathematical and Statistical Psychology, 57*(1), 173-181.